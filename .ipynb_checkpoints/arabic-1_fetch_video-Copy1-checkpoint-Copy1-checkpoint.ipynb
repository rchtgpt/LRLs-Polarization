{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2d164ba2-982f-4dd6-8445-c3fbc8d8f8dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMPORTS\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from datetime import date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9c93db-7d65-4360-8263-0654fdbeda10",
   "metadata": {},
   "source": [
    "# Fetch Video Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d17cdd2-1607-4d2a-9ad1-5bdd3cbdf0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining endpoint for accessing TikTok's API\n",
    "\n",
    "url = 'https://open.tiktokapis.com/v2/research/video/query/?fields=id,video_description,create_time,region_code,share_count,view_count,like_count,comment_count,hashtag_names,username,voice_to_text'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5d38800c-2f4a-4bcb-8ade-a589c235ed20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Define a new bearer token. Refer to Dev Documentation to see how to generate a new bearer token. \n",
    "# NOTE: The bearer token expires every 2 hours.\n",
    "\n",
    "headers = {\n",
    "    'authorization': 'bearer clt.optkb6putbakaMXodqPG9PCKIl7Ii0aaEnju0jxYgQ4iQFGV9lTWapiTGxl3',\n",
    "    'Content-Type': 'application/json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d3ccca92-edde-4406-8947-429238e60645",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the value of cursor being fed into the query 0\n",
      "the value of cursor being fed into the query 20\n",
      "the value of cursor being fed into the query 40\n",
      "the value of cursor being fed into the query 60\n",
      "the value of cursor being fed into the query 80\n",
      "the value of cursor being fed into the query 100\n",
      "the value of cursor being fed into the query 120\n",
      "the value of cursor being fed into the query 140\n",
      "the value of cursor being fed into the query 160\n",
      "the value of cursor being fed into the query 180\n",
      "the value of cursor being fed into the query 200\n",
      "the value of cursor being fed into the query 220\n",
      "the value of cursor being fed into the query 240\n",
      "the value of cursor being fed into the query 260\n",
      "the value of cursor being fed into the query 280\n",
      "new date to be explored is 2023-11-07\n"
     ]
    }
   ],
   "source": [
    "# Fetch all video details\n",
    "\n",
    "final_json = []\n",
    "username_vidID_pair = {}\n",
    "\n",
    "date_val = date(2023, 11, 7)\n",
    "todays_date = date.today()\n",
    "\n",
    "while (date_val < date(2023, 11, 8)):\n",
    "    prev_cursor = -1\n",
    "    cursor = 0\n",
    "    search_id = \"\"\n",
    "\n",
    "    current_date_vids = []\n",
    "\n",
    "    while (prev_cursor != cursor and cursor < 300): \n",
    "        print(\"the value of cursor being fed into the query\", cursor)\n",
    "\n",
    "        current_date = date_val.strftime(\"%Y%m%d\")\n",
    "\n",
    "        data = {\n",
    "            \"query\": {\n",
    "                \"and\": [\n",
    "                    {\"operation\": \"IN\", \"field_name\": \"hashtag_name\", \"field_values\": [\"غزة\"]}, # \"غزة\" means gaza in arabic\n",
    "                ]\n",
    "            },\n",
    "            \"cursor\": cursor,\n",
    "            \"search_id\": search_id,\n",
    "            \"start_date\": current_date,\n",
    "            \"end_date\": current_date,\n",
    "            \"is_random\": False \n",
    "        }\n",
    "        \n",
    "        response = requests.post(url, headers=headers, json=data)\n",
    "        json_data = response.json()\n",
    "\n",
    "        if 'data' in json_data and 'videos' in json_data['data']:\n",
    "            current_date_vids.extend(json_data['data']['videos'])\n",
    "            prev_cursor = cursor\n",
    "            cursor = json_data['data'].get('cursor', -1)\n",
    "            search_id = json_data['data'].get('search_id', \"\")\n",
    "\n",
    "        else:\n",
    "            print(json_data)\n",
    "            print(\"No 'data' key found in the response JSON.\")\n",
    "            break\n",
    "\n",
    "    for video in current_date_vids:\n",
    "        username_vidID_pair[video[\"id\"]] = video[\"username\"]\n",
    "\n",
    "    # Write the JSON data to a new file\n",
    "    final_json.append({\n",
    "                    \"date\": date_val.strftime(\"%Y%m%d\"), \n",
    "                    \"value\": {\n",
    "                        \"has_more\": json_data['data'].get('has_more', False), \n",
    "                        \"videos\": current_date_vids, \n",
    "                        \"cursor\": cursor\n",
    "                        }\n",
    "                })\n",
    "\n",
    "    date_val += timedelta(days=1)\n",
    "    print(\"new date to be explored is\", date_val)\n",
    "\n",
    "import json\n",
    "\n",
    "# Read existing data from the file\n",
    "try:\n",
    "    with open('arabic-video-data.json', 'r', encoding='utf-8') as json_file:\n",
    "        existing_data = json.load(json_file)\n",
    "except FileNotFoundError:\n",
    "    existing_data = []\n",
    "\n",
    "# Append new data to the existing data\n",
    "existing_data.append(final_json[0])\n",
    "\n",
    "# Write the updated data back to the file\n",
    "with open('arabic-video-data.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(existing_data, \n",
    "              json_file, \n",
    "              indent=2, \n",
    "              ensure_ascii=False\n",
    "             )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "06fb799e-8367-4408-8a88-91297e4e0f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('arabic-video-data.json', 'a', encoding='utf-8') as json_file: # Writes into a separate JSON file\n",
    "        json.dump(final_json, \n",
    "                json_file, \n",
    "                indent=2, \n",
    "                ensure_ascii=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "776b08cf-8d18-4ad0-99e8-5763fa1541f8",
   "metadata": {},
   "source": [
    "# Concatenate URLs from Video Data Fetched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b2ac46-7093-473f-bc0c-5b92c000ff3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def findURLs(username_vidID_pair):\n",
    "    \"\"\"\n",
    "    Using Video IDs and username, we can create the URL ourselves:\n",
    "\n",
    "    https://www.tiktok.com/@{username}/video/{video_id}\n",
    "    \"\"\"\n",
    "    for video_id, username in username_vidID_pair.items():\n",
    "        print(f\"https://www.tiktok.com/@{username}/video/{video_id}\")\n",
    "\n",
    "# Print all the URLs fetched for the given date range\n",
    "print(len(username_vidID_pair))\n",
    "findURLs(username_vidID_pair)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1344b1-bed0-4608-bda2-24111b09f2e5",
   "metadata": {},
   "source": [
    "# Extract Subsequent Hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c218556-f4af-40a4-8c13-aea777efadae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f54be80-9be4-45cb-9221-ef9ae85885bb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
